% ---------------------------------------------------------------------------------------------------------------------

\til{Intro to use of corpora --- basically what people do with them [note, not what they are, that comes later], what they contain (roughly) and special/general purpose.  See this as an intro for non-linguists and some signposting}


\section{Sampling in Corpus Linguistics}
\label{sec:sampling-corpus-linguistics}

The use of corpora for linguistic analysis is an long one---one justification for this is that the alternative to using some kind of corpus is either to manually seek evidence for a linguistic feature (something that very easily leads to pseudoscientific, unfalsifiable theories), or to inspect the "idea" of language that a native speaker (or speakers) posesses.

Whilst, doubtless, much good work has been done using these alternatives, they lack the objective and empirical epistemological possibilities that define the scientific process.  Examination of one's idea of language is likely to be influenced by the knowledge of a linguist, and seeking evidence for a theory in a language with unknown or poorly-defined bounds is likely to yield it regardless of the reality. % when observed from other contexts

Corpus methods, then, free linguistics from the alchemy of human understanding, providing a convenient empirical truth against which we may assess hypotheses.

The value of any inferences evidenced by this empiricism is, however, limited to the extent to which a corpus is associated to the language upon which we wish to comment.  It is this requirement that has raised most objections, for the concept of language is little understood and poorly defined even where people claim to understand it.  Regardless of controversies over form, it is accepted that any corpus representative of useful portions of a language must be very large indeed (though the definition of 'large' is also debated!).

Until recently, the task of gathering, processing, and inspecting large volumes of text was arduous enough to prevent its widespread appeal: some efforts were made before the era of computerisation, %CITE
, for example, did X etc \til{mention 1870s work, 1950's popularity}..% and there was a time when corpora were rather popular even without the benfits of computation

The introduction of programmable computing machinery, and (fast) electronic storage, opened the floodgates for easy, large-scale analysis of text.  This brought the second\td{does that mean we're on the third given its lull, or still second?} wave of corpus linguistics... \textsl{~~wavey wavey screen fades into next section like a flashback on 60's TV~~}


% TODO: a chronological history of corpora, [possibly just brown->lob->llc->bnc, p'raps include newswire mentions]

\subsection{A Brief History of Modern Corpora}
The Brown Corpus of Standard American English % CITE
is widely regarded as the first of the modern wave of corpora.  Built in the 60's, Brown's corpus was the first electronic-format general purpose corpusand was roughly one megaword in size, and contained 500 samples of 2000 words English text, taken according to a stratified sampling policy from works published in the United States in 1961.

The `Standard' in its name referred to Kucera and Francis' intent that it become a regular feature across corpus linguistics---this was quickly realised, as Brown became a \textsl{de facto} standard for American English.  In order to maximise the value of comparisons within studies, other general purpose corpora chose to mirror Brown's sampling policies.  

% --- 

The Lancaster-Oslo-Bergen (LOB) corpus was built as a British counterpart to Brown.  %CITE
It uses the same stratification and sampling strategy (with one or two more texts in certain categories) and thus comprises roughly a megaword of British English, as published in \td{when sources published?} %TODO: when?
.

% ---
\til{ Mention LLC, perhaps other specific corpora}

% --- 
\til{ BoE/COBUILD }

% ---
\til{ BNC, mention how it's become the 'new' de-facto standard, describe sampling and composition in some detail}

% ---
\til{ }

% ---
The rise of electronic communications has led to a reduction in the effort required to gather corpus data.  This has resulted in a great increase in the number of special-purpose corpora built for specific studies.  These corpora are generally more focused than the larger ones built up until the 90's, but some still claim to be general purpose (or at least have a `wide remit').  

% Move? [These corpora are often less widely used, and serve to illustrate one extreme discussed below, that the purpose of a corpus is important to its construction]

In this thesis, UI will be focusing on a specific (though popular) form of these corpora based on `web-as-corpus' (WaC) methods.  Please see section REF for more.




\subsection{What Makes a Corpus?} % 'What makes a corpus'
\til{Define the usage of corpus to be used in the thesis, in terms of properties that are desirable and undesirable from the literature.  This will likely not be the same as those in section 2.2.  This section should focus on a vaguely chronological recantment of the reasons for significant choices when building large and popular corpora, finishing off with what people use them for.  i.e. intent -> newer intent -> reality}

% Redo intro
The precise definition of a corpus is something that has been debated at length within the corpus linguistic community---the purpose of this section is not to define definitively what a corpus shall be, but instead to identify traits that are desirable and useful to the process of scientific inquiry.



In order to establish the important traits of corpora, it is wise to have an understanding of the motivation behind their existence.  Corpus methods are generally posited against two other methods of linguistic investigation: direct elicitation from a language speaker, and directed research into a linguistic feature.  Both of these pose significant scientific challenges---both are reliant on at least the linguist's intuitive view of language (one that could hardly be said to be representative of most language users), and both require the acquisition of data from within its context, something that is especially difficult given the varied and context-dependent complexity of language.

Corpora provide solutions to both of these issues.  In the former case, they provide an objective record of linguistic data that is free from all but the initial builders' linguistic choices (which, in the ideal case, may be documented and provided along with the data itself).  In the latter, they are as portable as any large volume of text, and may be annotated with context sufficient for a given linguistic task.


%------
The modern definition of a corpus has undergone a series of significant refinements thanks in part to the meteoric rise in both ubiquity and power of computing machinery.  Corpora are, with very few exceptions, electronic (with an increasing number documenting texts of electronic origin), multi-modal (covering a wide variety of methods of communication and their linguistic features), and annotated with linguistic data.  

% TODO: Meyer, McEnery and Wilson definitions

A corpus, then, is typically seen to be `a body of text sharing some important property that may be interrogated for some linguistic information'.  This is a fairly general definition, but takes into account the separation often made between haphazard collections of texts (often called \textsl{libraries} or \textsl{archives} with no relevant common features (be they internal or external) from a scientifically useful collection demarked by the boundaries of some homogenous notional entity.

Many authors %CITE
go further by stating that a corpus should be machine-readable, annotated with information useful to linguistic inquiry, built for a specific purpose or methodology, available for use in other studies, finite in size or even stratified to provide multiple possible analysis methods with valid data.  Whilst I do not consider many of these to be requirements for a scientifically useful corpus, many contribute greatly to [x]'s utility due to their alignment with common methodologies and uses---these will be examined in more detail later for their contributions.





% The definition of a corpus is one which has been oft-discussed with little agreement, indeed, as the field of corpus linguistics has progresssed its definition has gradually changed to suit the methodology of the day.  The Brown Corpus of Standard American English %CITE

% Examining the reasons why linguists first chose to use corpus methods reveals a number of important traits.  The first of these should be seen as its reliability---one of the major problems with assessing linguistic features by interrogation or directed research is that is it hard to establish known bounds of variability.  This inherent `fuzziness' in the method of inquiry, coupled with the context-dependent complexity of language itself, makes replication difficult.


% ----
% Brown's unique status afforded it status as a {\sl de facto} standard, and many subsequent corpora were built with similar foci.  Though the design of corpora has moved on significantly since those first efforts, this standard persists in its principles, and Brown's influence may be felt in the building and coding efforts of many general purpose corpora, to the point that many linguists are tempted to define corpora in terms of them. % TODO: move this elsewhere, but it's a good point

% Brown is widely regarded as the first of the modern age of corpora: its scale and electronic format differentiating it from previous collections and allowing automated analysis on a scale never before practical.




\subsubsection{Representativeness and Transferability}
Representativeness is, in effect, the holy grail of corpora.  It is the property that is to be maximised by adjustment of all others, and yet it is also the one that is dependent on enough factors to be poorly defined (by virtue of the difficulty of doing so).

The concept of representativeness is based not only on the definition of a population, but also the properties one wishes to generalise about, and the purpose for which one wishes to do so.  Various users of a corpus may find that, even for general-purpose corpora intending to represent the whole of a language (reference corpora), they produce unrepresentative findings where others' studies have great claims to accuracy. \td{Ahrg, this is terribly articulated}.

The concept of transferability % taken from sociology
is an alternative often applied to qualitative analyses by those in the social sciences.  It describes the likelihood that findings may apply to other members of a given, defined, population, without speculating as to the probability that a member of said population may be suitable for such a comparison.  This concept allows us to find evidence-based theories which hold true for groups specified by prior knowledge of the sample and human judgement of its relationship to the population.

It could be said that, prior to corpus methods, the best linguistics could do was the notion of qualitative transferrability.  Indeed, some may argue that the theoretically infinite population of utterances language makes possible means that any sample is incapable of being representative of language as a whole, rather that we are only able to generalise to observations of language [within finite time periods].

One approach to this is the use of monitor corpora, which grow along with their source material in order to, at any give time, represent the language used until that point.  This adds time as a piece of metadata that may be worked with in language models, though the rise in heterongeny this brings will reduce the power of the corpus when comparing to other, temporally restricted, corpora. \td{issues abound, perhaps discuss earlier/later at length instead}

\til{ Discuss representativeness in a more "linguistic" way including balance and choice of sampling frame.  Perhaps split into \textsl{GP}/\textsl{SP} corpora to discuss at more length.  Refer to web as corpus section for "we also discuss what we're sampling in WaC terms below...}

\til{Also, refer to the books more!}


\subsubsection{Size}
\til{This is the primary driver of the above, no-one really pins this down but survey some corpora and some more modern approaches (Kilgarriff's google-ology comments at the end would be good.  Link to web corpora for extreme bigness and ref to lower sections at end}


\subsubsection{Purpose}
The reason for sampling a given population is a crucial feature of corpora.  Not only does it define the level and type of metadata available (and the arbitrary definitions used therein), it has a large influence on the sampling frame used, and thus the validity of any generalisations made using said data.

\til{examples of purpose.  General/special.  Cover qualitative issues and quantitative issues of parameter estimation from biased statistics.}

Sub and re-sampling of corpora originally acquired for one purpose, though common, is likely to neglect the deep influences purposive or semi-purposive sampling is likely to have had upon the original corpus.  Correcting for these mis-matches may not be possible without extensive auxiliary data, which is often unavailable or impossible to accurately assign to existing texts.



\subsubsection{Normalised Form}
Many authors stipulate that a modern corpus should be electronic.  To generalise this position, they require that it is in some way processable by machines in a linguistically useful way.  This defines the format of not only the basic textual content, but also the availability of metadata at all levels (category/strata, document, word).

Efforts have been made %CITE EAGLES, TEI
to standardise the text type distinctions used in metadata, though there will always be the need to exceed or modify these for certain purposes\td{express arbitrary nature of these, explain the game-theoretic aspect} (see above, REF[purpose]).

To some extent, the form a corpus takes is defined by its content---any meaningful taxonomy is arbitrary and theory-laden---the best we can hope for is neutrality for the purposes of the task for which a corpus is being used (see purpose again...).  Internal text distinctions may be drawn using corpus-driven methods, however, these are often difficult to operationalise, or rely on assignment of names and descriptions that are themselves arbitrary again.  Taxonomic systems used for describing corpora and strata are designed to be maximally `purpose-neutral', and much effort is put into this.

\til{Describe taxonomy defining efforts and perhaps stratification in a way that is more tied to original corpus documentation, esp. stratification w.r.t. brown/brown-inspired corpora}


\subsubsection{Dissemination and Collaboration}
The ability for multiple researchers to access a corpus is one of the main benefits of corpus methods---corpus-based studies may be replicated and compared with absolute certainty of the empirical aspect of the research.

Historically, a number of design decisions have been made when sampling corpora in order to minimise the damage done by legal requirements from text publishers.  One of the most obvious of these is Brown's inclusion of two kiloword samples, rather than whole texts, in order to avoid many of the copyright issues associated with redistributing recently-published work.

Corpora often come bundled with restrictive licensing, something that is doubtless limiting to their scientific value.
\til{Hint at web stuff, open source corpus stuff, other scientific issues.}



\subsubsection{Summary}
\til{Define a phrase that, in a nutshell, defines what I'm using as a definition.}



\subsection{Validity Concerns in Corpus Building}
\til{Contain existing research on various aspects of validity.}
\subsubsection{Categorising Reference Corpora}
\til{Discuss the problem of meaningfully separating parts of a corpus for subsampling and description.}
\begin{itemize}
    \item Comparison to other corpora
    \item Balance, breadth and generalisability (inc. efforts to establish standards for these)
    \item Supcorpora, special-purpose-from-single-purpose
    \item Parallel and comparable corpora
\end{itemize}
\subsubsection{Dissemination}
\til{Descriptions of how to best spread corpora and the importance of sharing.  Cover the single-sample problem, open source corpora, twitter+news redactions, etc}


\subsubsection{Balance}
\til{Critiques of attempts to balance corpora against language (genres, special purpose corpus selection) and against one another (parallel corpora, brown, ae06/be06)}
\subsubsection{Replicability and Reliability}
\til{Linguistic reviews on `scientific issues' that do not centre on issues of text selection.  Include Open source corpora here, if they are not to be in the web section.}









% \til{The review of literature begins with a discussion of the current state of affairs w.r.t. sampling in corpus linguistics: how do people go about acquiring corpora, what their motivation and rationale is, and what people are currently developing in terms of sampling methodology.  I'll attempt to include some historical rationale too here.}
% 
% \subsection{Criticism of Current Data}
% \til{Here I will go on to discuss the failings of current widely-used lexical resources from the standpoint of their common use --- the section will focus on the representativeness of studies based on corpora as a method of commenting on their quality, and it's therefore necessary to draw the distinction between}
% \begin{itemize}
% 	\item General purpose corpora, and;
% 	\item Specialist corpora (and therefore some methods people use to build them).
% \end{itemize}
% 
% 
% 
% \subsection{Current Discussions of Representativeness}
% \til{Here I'll focus on work that is in the same vein as the thesis, i.e. how can we go about improving things?}



















% ---------------------------------------------------------------------------------------------------------------------
% Here there is a conceptual shift from "Current practice//problem" to "Ideal practice//solution"
\section{Formally Sampling Language}
% This will be a review of more formal sampling theory, comparing it to methods for acquiring language.
As we have seen in section~\ref{sec:sampling-corpus-linguistics}, corpus building efforts generally seek to solve a number of practical problems with quantitative linguistics, namely:
\begin{enumerate}
    \item Defining a finite and reliable linguistic resource (one that is static and entirely accessible);
    \item Replicating, comparing, and disseminating results.
\end{enumerate}

As such, the focus of many corpus building efforts \td{which corpus building efforts?}
has been largely on problems of procuring texts, selecting sufficiently broad categories of texts to be useful to many researchers, and managing the practicalities of text selection (i.e. by taking snippets of published and copyright works rather than their whole inclusion).

The use of corpora availed many statistical quantitiative techniques, each bringing a series of assumptions regarding not only the internal nature of the corpus, but also its relation to the larger population.  Whilst the validity of internal models has been discussed at length\td{where discussed?}
, little has been done to address the problems of external validity in this regard.

Therefore, in order to improve (and to assess) the value of a corpus to the wider field, it is necessary to inspect not only its empirical advantages (now well-determined for many frequently-used corpora) but also the potential value any given corpus building stratgy may yield in the ideal case.

In this section, I will be offering a critical description of how linguistic data may be sampled using existing, conventional, statistical techniques.  This comparison shall act as a gold standard against which existing (and future) efforts may be judged, as well as offering a stance from which to assess the successes and failings of current corpus-building efforts.



\subsection{The ideal Corpus}
\label{sec:sub:ideal-corpus}
\til{Based on current usage, but notably not restricted by methods and practicalities, review 2.1 with a view to extracting what we want from a corpus---address size, randomness, validity (internal + external), replicability, reliability, and flexibility.}

\subsubsection{Nature of Sample}
\til{Conventional corpora are guided by experts.  Do we want pure random corpora?  What does this even mean, what would the population be? language use or language exposure?  Defer some of these until the later sections of the thesis.}
\subsubsection{Validity}
\til{Following on from the above.  What does external validity become for a general/specific purpose corpus?  Do common corpora have any claim to external validity when used for qualitative/quantitative analyses of varying types?}
\subsubsection{Replication and Reliability}
\til{Corpora are hailed as being a basis for collaboration.  This is true of the most broken corpus, but a shared and accepted broken sample is worse than everyone sampling from the same population.  Address subsampling problems and issues of 're-usable bias' for very popular corpora.  To what extent are studies based on the same corpus comparable when using massively  different methodologies?}
\subsubsection{Size}
\til{How many words should a piece of string have in it?}
\subsubsection{Flexibility}
\til{Selection of data for qualitative research, or subsampling for quantitative, has the potential to undo all of the balancing above if not done properly.  How can this risk be minimised (guidelines for researchers, corpus size, specific corpus design, distributing tools with corpora)?}
% ---
\subsubsection{Summary}
\til{A simple, short and refer-able list of important things to work for in the below section.  Really, this might section up to here might be a good paper for CL or something.}

% \subsection{Paradigms for Sampling Language} % Kuhnian
% \til{The aim in this section is to draw out prominent linguistic concepts and justify sampling methods examined above in terms of their suitability to the theory of how we use language.  This is the tie to the personal corpus stuff, but will mention other ideas of what language is.}



\subsection{Comparison of Methods}
\til{Here I'll draw parallels between sampling methods and comment critically on their value.}
\subsubsection{Population}
\til{This is a largely linguistic issue of external validity, and will point back at section 2.1 a lot}
Linguistic issues (p'raps best taken from 2.1?):
\begin{itemize}
    \item How can we select a population closest to that discussed in section~\ref{sec:sub:ideal-corpus}?
\end{itemize}
Statistical theory:
\begin{itemize}
    \item How other fields with very complex parameter spaces do sampling
    \item Methods for population estimation given constraints from section~\ref{sec:sub:ideal-corpus}
\end{itemize}
\subsubsection{Sampling Frame}
\til{This is largely an issue of internal validity and reliability.}
Enumeration or bounding of a population:
\begin{itemize}
    \item General and special purpose corpora
    \item Sources of data (web, books)
    \item Time
\end{itemize}
Issues surrounding subsampling [general purpose corpora], and how this ought to be done

Sources of valid auxiliary information for sampling
\subsubsection{Sampling Methods}
\til{An overview of statistical sampling methods relevant to ling.}
Nonrandom methods, primarily included to compare against current ones:
\begin{itemizeTitle}
    \item[Purposive] Compare against current techniques.  Critique use of inferential stats on such corpora.  Big data perhaps illustrates flaws?
    \item[Snowball Sampling] Relevant due to web crawlers
\end{itemizeTitle}
Random sampling methods, as possible approaches
\begin{itemizeTitle}
    \item[Simple Random] Ideal case.  Focus on what makes it hard for linguistics.  Attempt to identify ways around this (empirical estimates of P()). Detasil practical issues with selection relative to stats.  
    \item[Stratified] How to select strata (w/ling. relevance)? Multi-dimensional strata. Inverse probability weighting.  PPS possibilities with web/offline.
    \item[Multistage ~and~] IPW, how to balance samples and...
    \item[Cluster] Website-wide clusters.  Relate to the structure of data, with publishers/websites forming clusters.
    \item[Adaptive] Perhaps too nonrandom for this section?  Offers a way to balance corpora with linguistic sampling frame.  Select frame using multistage sampling?
\end{itemizeTitle}

\subsubsection{Size and Power}
\til{Methods for selecting size and power.}
Linguistic criteria for selecting sizes (relate to ling. lit above) [common models, sufficient representation of odd features, breadth of coverage].

Existing corpora's approach (refer to 2.1 mainly).  Focus on the rise of big data+simple models showing that p'raps small data is biased ("bad smells").
\subsubsection{Reweighting}
\til{Multistage sampling and bias estimating with and without using auxiliary data.}
For multistage designs, how large should the initial corpora be? Is it small enough to be driven by the user's data or selection of medoid items?

Auxiliary Data:
\begin{itemize}
    \item Sources of valid auxiliary data (without inheriting the bias of existing corpora, ideally)
    \item How broken manual resampling of corpora is at the moment, and how people *want* to do it.
\end{itemize}
\subsubsection{Bias Estimating}
\til{This covers the problem of evaluation, how do we know that a corpus is better than another without a gold standard?  Does a gold standard actually exist, but we are not using it as such?  How can we ensure change goes in the correct direction?}
Repeated resampling and benchmarking.

Comparison to auxiliary data, suitable distance metrics, and criteria for acceptance.








% Now we shift onto the low-level focus of the thesis, web issues
\section{New Technologies} % "Opportunities and Challenges"
\til{New technologies have "fixed" many issues surrounding the availability of data, but introduced their own intricacies.  Things such as text to speech, life corpora and the web will be introduced here, after which the web will be focused on.  The intent is to frame web corpora in terms of their emerging nature w.r.t. other sources of data, and to state that we wish to exceed, rather than emulate, the quality of existing corpora.}


\subsection{Web Corpora --- Challenges}
\til{This section will cover, in general, web-related concerns.  The aim is to provide a comprehensive overview of the challenges to good scientific practice and representative samples.

I envisage this section having a subsection for each issue, for example, attrition, cleaning of data, identification of documents, etc.}

%CITATION: "Googleology is bad science", kilgarriff
