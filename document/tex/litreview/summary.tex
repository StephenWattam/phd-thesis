
Conventional corpus sampling techniques are, fundamentally, based on those used elsewhere.  There is, however, much confusion on the topic, and unwarranted debate over whether or not corpora are comparable to typical samples.

Much of this debate has stemmed from tradition, being sparked by the complexity of corpus designs such as Brown's, which relied heavily on expert opinion and inclusion of text according to a deliberately non-representative policy.  Much of this subjectivity is, in reality, a reaction to practical challenges that faced the first corpus construction efforts.

Many of these practical challenges have either changed in nature, or been solved.  Digitisation and POS tagging are now largely automatic affairs, and documents for inclusion are often born digital.  For UK researchers, there is even relief from a number of intellectual property issues.

Unfortunately, however, some have proven harder to solve.  There are still large challenges to the problems of population definition, and definition of a widely-agreed-upon taxonomy for genre definition.  Additionally, access to documents, even where technically possible, is often restricted by private corporations, or filtered through systems such as search engines that act as black boxes.

These remaining challenges are still limiting the corpus building process, and prevent the use of the most quantitative random sampling techniques.  Even those that are part expert-informed, such as stratified sampling or cluster sampling, require widespread agreement on taxonomy selection.  It is unlikely that there will be any one answer to such theoretical issues, as these must be defined relative to the research question.

The Web-as-Corpus movement offers a democratisation of the corpus building process by easing a number of the retrieval and enumeration problems.  These come with a significant challenge of their own, however, in that each user must then perform all of the stages of a corpus construction effort: from unambiguously specifying population parameters to cleaning and preparing the data.

This process can, at least, be automated.  In so doing, it is possible for researchers to vary their corpus designs and tailor them to meet individual needs.  For this to occur, tools and methods must be produced that are able to take design goals and, without significant further effort, produce corpora from them.

The role of this thesis is to explore this space, investigating corpus sampling and identifying areas where WaC approaches may mitigate remaining issues.  The ultimate goal is to provide methods and tools which allow users to rationalise and operationalise design criteria to produce their own valid and useful corpora.


