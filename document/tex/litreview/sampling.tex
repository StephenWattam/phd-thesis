% This will be a review of more formal sampling theory, comparing it to methods for acquiring language.


Many of the problems listed in section~\ref{sec:litreview-corpora} may be mitigated with careful sampling.  There are a great number of available sampling strategies, and the purpose of this section is to review those which are suitable for use with text data.


%- *NB: I don't wish for this to get too prescriptive.  It's intended as an overview of an idealised procedure, rather than a "how to", which will basically come later in a far more practical form*

\subsection{Population Definition}
The population covered by a corpus is likely to be defined in terms of social demographics, linguistic features, or media type.  The manner in which each of these may be estimated, enumerated, and sampled is highly variable mainly due to the availability of auxiliary data.

An accurate population definition is necessary for two purposes.  At one level, specification of this will define the bounds of external validity, guiding use of the corpus and defining the set of problems for which it is useful.  A second reason for accurate population specification lies in estimation of its size, which is necessary for power analysis and sample size calculation.

% Discuss justification of external validity, how this must be strict for use with general-purpose corpora
Ultimately, any statement of population coverage will be unique to the corpus being built.  In the case of general-purpose corpora, documentation of this population is particularly important, as the corpus is likely to be reused and possibly subsampled.  Further, the relationship each sample point within the corpus has to the overall population should be annotated, so that any resampling is defensible.

% Discuss causal theories of language, and how these must inform a choice
If sampling from linguistic features, the population items are taken from may be purely theoretical.  This initially would seem to violate the principles of corpus linguistics sampling language `as it is used', however, each example is necessarily also covered by a demographic population from which those data were taken.  It is particularly important that both are documented, especially given disagreements between theories regarding language use (for example, some researchers may consider two features related where others do not)\td{examples}.


\til{p'raps examples of how corpora do this right now, and other others do this?}

\til{mention external nature of definition, homogeniety of population (though the latter might be less important given the purpose comments in the corpus section)}



% 
% \begin{itemize}
%  \item Applications to language (not sure of any in the abstract, todo: find some.)
%  \item Applications to the web (google/yahoo estimation papers from DA bibtex)
% \end{itemize}








\subsection{Sampling Frame}
Definition of a sampling frame is a very similar problem to the population definition above, except that, where a population definition may relate to the aspects being studied, definition of a sampling frame is necessarily performed in terms of texts themselves.

One significant challenge here is that a well defined population may yield a very poorly defined sampling frame (or one which only matches under certain strong assumptions).  The difficulty of acquiring texts from many different sources means this is a particularly pertinant issue to corpus validity.

\til{say what a sampling frame is :-)}

\til{Enumeration of sampling frame, is it necessary for each sampling method?}



\subsubsection{Sampling Unit and Linguistic Dispersion}
\label{sec:sampling-unit-and-dispersion}
One of the key problems in determining an agreed-upon structure for general-purpose corpora is the selection of a sampling unit.  The sampling unit for many studies is self-evident: a cross-sectional sample of heights would, for example, be done on a person-by-person basis.  In such a case, there are obvious theoretical reasons to select the individual for study.

Linguistics is faced with a particular challenge in this regard, on a number of theoretical points that would seem to defy answers for the forseeable future:

\begin{itemize}
    \item Many studies of language require wildly different spans of text: those using lexical collocations have decided upon a 5-word limit\td{cite sinclair?}, whereas those studying sentence structure will demand more data, and some require whole documents in order to examine narrative and discourse.
    \item There is no agreement upon the human limits of perception for linguistic features, and so the above is unlikely to be answered by an authoritative model.
    \item Due to copyright concerns and the overheads associated with digitising and normalising the format of texts, sampling smaller portions of text is often easier, except that:
    \item There is an overhead associated with looking up each text, making sampling of particularly small units from many texts difficult.
\end{itemize}


These issues, and the dearth of any immediate solution thereto, has led to a situation where corpus sizes are commonly measured in words.  This, in turn, has raised some severe issues for corpus methods, since they must handle the lack of consistent inter-word variation when performing word-level variation.

The disparity between the unit of sampling (word) and the unit of analysis (often text, author, etc.) has led to much criticism aimed at statistical methods (which buy their validity from assumptions of randomness) when applied to corpus data\td{cite kilgarriff's h0 questioning paper, others}.  This criticism is well-placed, and has led to a large amount of reseach into methods that are able to model and compensate for the nonrandom (but stochastic) `dispersion' of a linguistic feature throughout a corpus\td{massive string of cite}.

This approach may be seen as a way of ensuring that the practical limitations mentioned above are respected whilst extracting maximum value from the data gathered therefrom.  This is undoubtedly a valuable endeavour for some uses of such corpora, however, it is no substitute for sampling using the correct unit to begin with.  This argument becomes particularly salient when one sees that each category within a popular corpus such as the BNC may hold only tens of texts, rendering a sample of authors, for example, low enough to damage the validity of even very unambitious study designs.

\paragraph{}
An alternative viewpoint is extolled by Evert's `library metaphor' paper, in which he posits that the source of randomness comes from sampling:

\begin{quote}
Something about getting a random word, then getting another random word etc.
\end{quote}

Though he goes on to publish a number of times on the subject of applying dispersion measures in linguistics (curiously contradicting a number of his arguments by implication), this publication serves to hint at the purist approach to sampling unit selection.

For the purposes of this thesis I shall be attempting to steer clear of the theoretical basis of sampling unit selection, except to note that the policy of applying dispersion measures after sampling is a poor substitute for appropriate initial selection of data.  As we shall see in later sections, the availability of WaC methods allows us to mitigate some of the practical barriers to ensuring measurement- and sampling-unit coordination.




\subsubsection{Auxiliary Information}
Auxiliary information may be used from a wide variety of sources to inform the specification both of a population and of a sampling frame.  The source of this information will vary depending on the focus of the corpus, however, there are some obvious sources of authoritative data:

\begin{itemize}
    \item Social surveys (for demographic, attitudinal information)
    \item Previous corpus building efforts
    \item Smaller-scale research on specific issues
\end{itemize}



\til{ More detail.  Methodological stuff.
    use of auxiliary information iteration to inform selection of texts}









% Much of this list belongs in the sampling methods bit below.
% \begin{itemize}
%     \item Subsampling with/without weights
%     \item Using auxiliary information to weight strata
%     \item artificial inflation of interesting sections of the population (modelling, stratification)
% \end{itemize}

\subsection{Sampling Method}

\til{A discussion of what each does, and where it seems to be used, split up into nonrandom:}

\til{Difficulties in random sampling due to the above problems with specifying a sampling frame}

\til{Opportunities in nonrandom sampling.  Cover nonrandom sampling used elsewhere where similar problems exist}


\subsubsection{Random}


\begin{itemize}
    \item SRS (more special purpose focus, mention use in re-sampling)
    \item Stratified (focus on this, mention IPW, use of external data to find proportions, primary dimensions of variation and link to taxonomic stuff)
    \item Multi-stage (link to above, perhaps belongs in that section)
    \item Cluster (may simplify some practical issues)
    \item Adaptive (possibly introduce later since it's a plausible solution to some issues, but not currently used.  Some parallels with the iterative method)
\end{itemize}

\subsubsection{NonRandom}

\begin{itemize}
    \item Snowball sampling (web crawlers)
    \item 'Purposive' in general (applies slightly to many things, perhaps worth mentioning but not really labouring)
\end{itemize}












\subsection{Size and Power}
\til{Perhaps go over hypothesis testing/types of error?  Is that too simple to put here?}
Methods for selecting sample sizes, (stratum sizes), sampling unit sizes [last of these is mainly linguistic, but might be worth mentioning].

\subsubsection{Population Size Estimation}
\til{Write up notes, cover various methods and assess suitability.  Cover existing efforts from SE literature (perhaps later in web stuff)}
% http://www.healthknowledge.org.uk/public-health-textbook/health-information/3a-populations/methods-population-estimation-projection
% http://www.jstor.org/discover/10.2307/3797301?uid=3738032&uid=2&uid=4&sid=21102138383343
% http://en.wikipedia.org/wiki/German_tank_problem
% http://www.cals.ncsu.edu/course/fw353/Estimate.htm


\subsection{Sample Size and Power}
The process of selecting an appropriately large sample for a given test, and ensuring that its results afford meaningful analysis, is called power analysis.  This is dependent upon four variables, each of which may be derived as a function of its bretherin:

\begin{itemizeTitle}
\item[Desired Effect Size] The minimum difference between the hypothesised value being tested and the null, that is, the smallest change we deem to be scientifically meaningful.  This may be difficult to determine when working with complex reductions of the dimensions within corpora, but should be related back to the original data in order to be interpreted anyway. \td{"The degree to which the null hypothesis is false" Cohen "Statistical power analysis for the behavioural sciences"}
\item[Probability of Type I Error] The confidence we wish to have in any result rejecting the null hypothesis, that is, the probability we will correctly reject the null hypothesis and state that there is a difference between the groups we have identified.
\item[Sample Size] The size of the sample.  Assuming it is taken without bias, this affects the amount of sampling error in the study---larger samples will exhibit less error (on top of the natural population variation).
\item[Statistical Power] The probability that a test will correctly reject $H_0$.  Like $\alpha$ above, this is conventionalised and should be chosen to fit the circumstances.
\end{itemizeTitle}

A test that is specified so as to be higher powered will be likely to detect smaller effects, to the point where it may detect effect sizes that no longer have ramifications for the real world.  Conventionally, this is warned against for practical and ethical reasons: the overheads required in gathering the data impose a practical disadvantage on the study.  This is less of an argument, however, for shared resources such as corpora, for which we may be tempted to say ``the more data the better'' if it were not for the insane complexity of larger portions of language, implying that more will never be enough for some anyway.  The question here is who those some are, and what portion of those wishing to use a corpus they comprise.  We shall revisit this conundrum later.

Where data is as dimensional as linguistic data (and formal statistics often explain very small proportions of variance), the detection of very small changes in a parameter of interest is also likely to represent spurious influence, evidencing not the alternative hypothesis presented, but instead some correlational quirk that may not be relied upon.  Philosophical purists may at this point be objecting to the implication that rejection of the null hypothesis implies acceptance of the alternate given.  They are right, of course, but in practice the distinction is respected less than it perhaps ought to be.



Underpowered tests suffer an altogether more familiar failure, in that they are unlikely to detect an effect where one actually exists.  Where this is the case it is largely impossible to determine if any observed effect is down to meaningful variation in the sample used (which should warrant further study) or simply due to the sample size being too small (which should [ideally] not).

This would seem to be of epidemic proportions in linguistics, especially where larger features are studied, with researchers often noting that an effect is interesting but statistically unconfirmable:
\begin{quote}
QUOTE STUFF FROM PEOPLE
\end{quote}
\til{Quote a load of things where people say "There's not enough data to prove it, but this effect looks interesting"}









Where a corpus is built in a special-purpose manner, the desirable sample size may be authoritatively calculated a priori, on conditions defined by the intended study design.\td{note how rarely this is done}  Where general-purpose corpora are defined, however, this is unlikely to be accurate due to the disparate study designs used after sampling is complete (see~\ref{sec:sampling-unit-and-dispersion} above).

It would seem that general-purpose corpora in their current form, as large shared pre-built repositories of text, are doomed to one of two fates: either they will be so large as to be difficult-to-process (containing enough text to satisfy power requirements of studies focusing on large units of text), or they will be incapable of offering valid insight into larger features due to insufficient sample sizes.






\subsubsection{Methods for Sample Size Calculation}

\til{Discuss methods for estimating sample size.}
\til{Debate suitability for various uses, esp. for general purpose corpora.  Focus on Zipfianness.}
\til{Cover saturation measures, 'new information' approaches}

% \begin{itemize}
%     \item Criteria for selection
%     \begin{itemize}
%         \item purpose-based models [should be big enough for x]
%         \item sufficiency/internal measures [should contain n xs]
%         \item breadth/variation [should contain n types of x]
%     \end{itemize}
%     \item Big data's approach
%     \item Size of auxiliary data for multi-stage designs
% \end{itemize}









% TODO: this section might not belong, or it might be best off later
\til{ The section below is probably best off being placed later, or at least where its focus is more well-defined}
\subsection{Post-hoc/Reweighting(/representation)}
\til{this seems to conflate the stratification stuff, restructure}
Methods for upping weights in line with auxiliary data, even of existing corpora.

\begin{itemize}
    \item Establishing weights using auxiliary data
    \begin{itemize}
        \item possible sources of valid data
        \item existing manual resampling by selection of categories (compare to above method)
    \end{itemize}
\end{itemize}












\subsection{Bias Estimation and Evaluation}
Methods for evaluating and comparing corpora

% http://en.wikipedia.org/wiki/Mean_signed_difference ?
% http://en.wikipedia.org/wiki/Mean_absolute_error

\begin{itemize}
    \item Bootstrapping
    \item Comparison to other corpora (validity, meaning, can we trust previous corpus to be a gold standard?)
    \item Comparison to humans (heuristics, summarising, "getting to know your corpus")
\end{itemize}





% Below is OLD as of 02/02/13
% 
% As we have seen in section~\ref{sec:sampling-corpus-linguistics}, corpus building efforts generally seek to solve a number of practical problems with quantitative linguistics, namely:
% \begin{enumerate}
%     \item Defining a finite and reliable linguistic resource (one that is static and entirely accessible);
%     \item Replicating, comparing, and disseminating results.
% \end{enumerate}
% 
% As such, the focus of many corpus building efforts \td{which corpus building efforts?}
% has been largely on problems of procuring texts, selecting sufficiently broad categories of texts to be useful to many researchers, and managing the practicalities of text selection (i.e. by taking snippets of published and copyright works rather than their whole inclusion).
% 
% The use of corpora availed many statistical quantitiative techniques, each bringing a series of assumptions regarding not only the internal nature of the corpus, but also its relation to the larger population.  Whilst the validity of internal models has been discussed at length\td{where discussed?}
% , little has been done to address the problems of external validity in this regard.
% 
% Therefore, in order to improve (and to assess) the value of a corpus to the wider field, it is necessary to inspect not only its empirical advantages (now well-determined for many frequently-used corpora) but also the potential value any given corpus building stratgy may yield in the ideal case.
% 
% In this section, I will be offering a critical description of how linguistic data may be sampled using existing, conventional, statistical techniques.  This comparison shall act as a gold standard against which existing (and future) efforts may be judged, as well as offering a stance from which to assess the successes and failings of current corpus-building efforts.
% 
% 
% 
% \subsection{The ideal Corpus}
% \label{sec:sub:ideal-corpus}
% \til{Based on current usage, but notably not restricted by methods and practicalities, review 2.1 with a view to extracting what we want from a corpus---address size, randomness, validity (internal + external), replicability, reliability, and flexibility.}
% 
% \subsubsection{Nature of Sample}
% \til{Conventional corpora are guided by experts.  Do we want pure random corpora?  What does this even mean, what would the population be? language use or language exposure?  Defer some of these until the later sections of the thesis.}
% \subsubsection{Validity}
% \til{Following on from the above.  What does external validity become for a general/specific purpose corpus?  Do common corpora have any claim to external validity when used for qualitative/quantitative analyses of varying types?}
% \subsubsection{Replication and Reliability}
% \til{Corpora are hailed as being a basis for collaboration.  This is true of the most broken corpus, but a shared and accepted broken sample is worse than everyone sampling from the same population.  Address subsampling problems and issues of 're-usable bias' for very popular corpora.  To what extent are studies based on the same corpus comparable when using massively  different methodologies?}
% \subsubsection{Size}
% \til{How many words should a piece of string have in it?}
% \subsubsection{Flexibility}
% \til{Selection of data for qualitative research, or subsampling for quantitative, has the potential to undo all of the balancing above if not done properly.  How can this risk be minimised (guidelines for researchers, corpus size, specific corpus design, distributing tools with corpora)?}
% % ---
% \subsubsection{Summary}
% \til{A simple, short and refer-able list of important things to work for in the below section.  Really, this might section up to here might be a good paper for CL or something.}
% 
% % \subsection{Paradigms for Sampling Language} % Kuhnian
% % \til{The aim in this section is to draw out prominent linguistic concepts and justify sampling methods examined above in terms of their suitability to the theory of how we use language.  This is the tie to the personal corpus stuff, but will mention other ideas of what language is.}
% 
% 
% 
% \subsection{Comparison of Methods}
% \til{Here I'll draw parallels between sampling methods and comment critically on their value.}
% \subsubsection{Population}
% \til{This is a largely linguistic issue of external validity, and will point back at section 2.1 a lot}
% Linguistic issues (p'raps best taken from 2.1?):
% \begin{itemize}
%     \item How can we select a population closest to that discussed in section~\ref{sec:sub:ideal-corpus}?
% \end{itemize}
% Statistical theory:
% \begin{itemize}
%     \item How other fields with very complex parameter spaces do sampling
%     \item Methods for population estimation given constraints from section~\ref{sec:sub:ideal-corpus}
% \end{itemize}
% \subsubsection{Sampling Frame}
% \til{This is largely an issue of internal validity and reliability.}
% Enumeration or bounding of a population:
% \begin{itemize}
%     \item General and special purpose corpora
%     \item Sources of data (web, books)
%     \item Time
% \end{itemize}
% Issues surrounding subsampling [general purpose corpora], and how this ought to be done
% 
% Sources of valid auxiliary information for sampling
% \subsubsection{Sampling Methods}
% \til{An overview of statistical sampling methods relevant to ling.}
% Nonrandom methods, primarily included to compare against current ones:
% \begin{itemizeTitle}
%     \item[Purposive] Compare against current techniques.  Critique use of inferential stats on such corpora.  Big data perhaps illustrates flaws?
%     \item[Snowball Sampling] Relevant due to web crawlers
% \end{itemizeTitle}
% Random sampling methods, as possible approaches
% \begin{itemizeTitle}
%     \item[Simple Random] Ideal case.  Focus on what makes it hard for linguistics.  Attempt to identify ways around this (empirical estimates of P()). Detasil practical issues with selection relative to stats.  
%     \item[Stratified] How to select strata (w/ling. relevance)? Multi-dimensional strata. Inverse probability weighting.  PPS possibilities with web/offline.
%     \item[Multistage ~and~] IPW, how to balance samples and...
%     \item[Cluster] Website-wide clusters.  Relate to the structure of data, with publishers/websites forming clusters.
%     \item[Adaptive] Perhaps too nonrandom for this section?  Offers a way to balance corpora with linguistic sampling frame.  Select frame using multistage sampling?
% \end{itemizeTitle}
% 
% \subsubsection{Size and Power}
% \til{Methods for selecting size and power.}
% Linguistic criteria for selecting sizes (relate to ling. lit above) [common models, sufficient representation of odd features, breadth of coverage].
% 
% Existing corpora's approach (refer to 2.1 mainly).  Focus on the rise of big data+simple models showing that p'raps small data is biased ("bad smells").
% \subsubsection{Reweighting}
% \til{Multistage sampling and bias estimating with and without using auxiliary data.}
% For multistage designs, how large should the initial corpora be? Is it small enough to be driven by the user's data or selection of medoid items?
% 
% Auxiliary Data:
% \begin{itemize}
%     \item Sources of valid auxiliary data (without inheriting the bias of existing corpora, ideally)
%     \item How broken manual resampling of corpora is at the moment, and how people *want* to do it.
% \end{itemize}
% \subsubsection{Bias Estimating}
% \til{This covers the problem of evaluation, how do we know that a corpus is better than another without a gold standard?  Does a gold standard actually exist, but we are not using it as such?  How can we ensure change goes in the correct direction?}
% Repeated resampling and benchmarking.
% 
% Comparison to auxiliary data, suitable distance metrics, and criteria for acceptance.
% 
% 

