

It is clear that there are significant differences between the language experienced by the subject here and the proportions of any BNC-like corpus.  These differences are partially explainable by temporal differences (such as the rise of the web and portable availability of broadcast media) and partially by demographic.  Those non-demographic differences imply that the BNC would apply poorly to the population as a whole, if used as a sample of language exposure.

There are a number of methodological challenges that continue to prevent application of the methods described here to larger populations.  These are either due to the problems inherent in sampling multi-modal data in the first place (digitising photographs or transcribing audio), or the processing required to transform data into a usable form (models of attention).

It is hoped that further work will be able to develop these methods in order to mitigate these issues, at least for certain applications.  However, the utility of these methods is retained under less ambitious conditions of restricting a combination of the domain (for example, only sampling web histories or work-day language use) and the population (i.e. only people very similar to myself).

The practical issues encountered during sampling are largely minor, and modern portable technology proved decisive in making capture of hitherto-unseen (or at least widely ignored) sources of text possible in-the-field.  The census design lends an empirical justification to inclusion of these genres in larger general-purpose corpora, however, we are unable to formally generalise with confidence to demographics other than that of the subject covered.

Of particular note (and perhaps greatest generalisability) is the number of words used throughout the sampling period.  Almost a million words were input and output by a single individual over a two week period.  Since it is reasonable to deduce that this sampling is at best representative only of a normal working week for a single individual, it is rational to suppose that a corpus purporting to cover the whole population of a country demands a sample size far greater than many existing corpora.


This would seem to form an argument that it is simply not cost-effective to build a conventional general-purpose corpus large enough to represent large populations, suggesting that the focus should lie in those built for more specialist purposes, or those sampled non-probabilistically.  Here, the extreme size of web corpora may be well justified, so long as they can be shown to have been sampled rigorously.


This suggestion is reinforced by the obvious variability in the proportions of texts taken from each source, which will vary greatly by lifestyle.  Indeed, it seems that the measure of one's lifestyle by text source is a particularly direct way of characterising inter-person variability, and further work may be focused on this problem as a way of simplifying the methods described here.


Of interest to this thesis is the high level of detail that may be captured using this method.  The census design affords full coverage of a given area about which we may wish to generalise, and the detail it is possible to capture this way makes the data ideal as a `seed' for constructing larger corpora with comparable properties.  Application of these methods, as well as those using auxiliary data mentioned above, will hopefully render this sampling method a complementary one, to be added to the collection of existing corpus designs.
