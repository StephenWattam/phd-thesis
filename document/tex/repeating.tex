
\section{introduction}
The validity of a corpus with regards to a scientific study is based upon the quality of its link to the empirical, observable truth.  As multiple theorems are tested against this truth they are necessarily discounted if failing or, passing, held only as not-yet-disproven.

Indeed, for many principles and theories to become widely-held beliefs it is necssary to test them many times against the ground truth.  This is one area where corpora have proven damaging---the universality of general purpose corpus designs, whilst enabling the initial inquiry, has served to damage the capacity researchers have to repeat their studies.

\til{it is worth noting here that it's still cheaper to use one than to not have them at all, so they are a net gain}

Where corpora are particularly difficult to construct (for example speech, some specialist populations) this problem abounds---there may well be only one or two corpora against which to test a hypothesis, something that amounts to limits confirmation especially if earlier findings on that corpus are used as the motive for research \todo{this amounts to data-dredging and is fallacious}

In a world where the acquisition of corpora is relatively cheap and simple, this restriction is simple to lift---each researcher may simply re-acquire data according to the policies of the original work, creating a comparable but non-identical corpus.  This would constitute an expansion of the coverage of the original, further testing the original hypothesis as well as avoiding the texas sharpshooter fallacy as corpora are continually subsampled for different purposes.

The ability to reconstruct corpora for a given task also yields legal benefits, as the corpus itself need not be conveyed, only a manifest sufficient to test comparability. 

\til{more...}

% --- signposting

The idea of being able to resample a corpus yields some other valuable use-cases, such as repairing older corpora to include more dates (like an after-the-fact monitor corpus) or reweighting a corpus to construct a subset that is based on more than simply the whim of a single researcher.  These possibilities will be explored here, with a focus on applying CDL and web data in their solutions.




\section{Use Cases for Corpora}
Using methods from above, the idea here is to describe how to best disseminate web corpora in a legal, reuable and scientifically valid form.  The introduction will include overviews of how people currently do it, before launching into the subsections that cover problem and proposed solutions.


\subsection{Rebuilding a Corpus}
\todo[color=blue!20, noline]{WHEN}
Outline why we'd want to rebuild a web corpus in order to promote its linguistic coverage and representivity.  Produce, detail and evaluate either a method, or a piece of software based on that method, to augment or repair a corpus (software would tie in nicely to the sampler higher up).


\subsection{Reweighting a Corpus}
\todo[color=blue!20, noline]{WHEN}
Explain how the size of web corpora means reweighting and resampling are expecially pertinent approaches; produce, detail and evaluate a method or software tool (as above).  Note that, algorithmically, this task is not so different to the above, so might be merged into it.


\section{Evaluation of Dissemination Methods}
\todo[color=blue!20, noline]{WHEN}
Evaluate the capabilities of methods for rebuilding and resampling with some test data (again, frame with linguistic content).  Special care must be taken to evaluate similarity in a way that doesn't simply extract one or two dimensions from text, hence the subection discussing this at length.  Perhaps the subsection belongs above this section as a pre-discussion of evaluation methods.


% 
% % Moving from problem to solution again
% \section{Tools Based on the Chosen Methods}
% A major contribution here is to be a suite of software to allow people to put some of these principles into practice.  The idea is to use this as a separate paper, and merge it in here, so the subsections are quite fluid.
% 
% \subsection{Details of Implementation}
% Outline the design choices made to avoid each of the issues.  There'll be a focus on having some kind of sampling strategy descriptor because it ties nicely to the next chapter.
% 
% \subsection{Evaluation}
% Here  I'll attempt to evaluate the quality of sampling.  This will be done by comparison of results from linguistic analyses, such as keywording, as well as in comparison to the findings of search-engine document attrition studies (these will validate the findings to some extent, rather than merely stating that the corpus is different).
% 
% The big question here is how I evaluate corpus quality without using a larger (ideally more biased) corpus.  Chances are this method will become a subsection of its very own.
% 


\section{Building/Matching a Sample}
Relationship to CDL (reverse, trying to follow/fit model)

\subsection{Heuristics}
List of heuristics and rationale for each

\section{Implementation}
What form the tool takes, and why (p'raps largely relegated to an appendix)?


